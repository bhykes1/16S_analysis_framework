---
title: "16S Analysis Framework"
author: "Scott A. Handley"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: html_document
---

# Background

Basic analytic framework for processing 16S rRNA gene amplicon data. Each R chunk represents a specific analysis. Depending on the makeup of the data, such as sample names, variable names or data subsets some R chunks are optional or will need modification as needed.

The code chunks perform the following functions:

1) Data and environment initiation
2) Factor reordering and renaming (optional)
3) Data assessment
4) Taxon prevalence estimations and filtering
5) Data transformation
6) Subsetting (optional)
7) Community composition plotting
8) Alpha diversity analysis
9) Beta diversity analysis
10) Constrained Correspondence Analysis (optional)
11) Differential abundance testing

To be added: Proscutes, ANCOVA

The example data are dada2 amplicon sequence variants. Briefly, extracted nucleic acid from stool samples collected from individually caged mice were amplified in triplicate using primers specific for the V4 region using primers 515F/806R. One group of mice (n=30) were treated with ampicillin for 3 days, and the other a vehicle control (n=15).

##Data and environment initiation

We will begin by customizing our global settings, activating packages and loading our data into R using the following steps:

1) Set global knitr options
2) Set global ggplot2 theme and options
3) Load libraries
4) Load data

###Set knitr global options

Useful for standardizing how R chunks are handled by knitr. There are quite a few options you can use in this section which can be [read about here](https://yihui.name/knitr/options/), however, setting a standard figure height and width as well as an output directory and prefix name for all knitted figures can be useful.

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=8,
                      fig.height=6,
                      fig.path="./figures/",
                      dev='png',
                      warning=FALSE,
                      message=FALSE)
```
##Load libraries

```{r initiate-environment}
library("tidyverse")
packageVersion("tidyverse")
library("phyloseq")
packageVersion("phyloseq")
library("RColorBrewer")
packageVersion("RColorBrewer")
library("vegan")
packageVersion("vegan")
library("gridExtra")
packageVersion("gridExtra")
library("knitr")
packageVersion("knitr")
library("DESeq2")
packageVersion("DeSeq2")
library("plotly")
packageVersion("plotly")
library("microbiome")
packageVersion("microbiome")
library("ggpubr")
packageVersion("ggpubr")
library("randomForest")
packageVersion("randomForest")
library("data.table")
packageVersion("data.table")
library("corrplot")
packageVersion("corrplot")

```
##Set global ggplot2 theme and options. This sets the plotting aesthetics for every ggplot2 for the rest of the document.

```{r global-theme-settings, include=FALSE}
# Set global theming
theme_set(theme_bw(base_size = 10,
                   base_family = "Helvetica"))

```
##Read in your data

The output from a standard dada2 workflow should be an RDS file. In this case the file is called *ps0.rds*. You may have already merged your mapping file data (sample variables) with the rds file. However, you will likely add or modify this mapping file as you progress, so it is useful to initiate an import/merge of a modifiable mapping file.

```{r initiate-data}
# Read in an RDS file containing taxonomic and count information
ps0 <- readRDS("ps0.rds")

# Read in a mapping file containing sample variable information
map <- import_qiime_sample_data("mapping.txt")

# Merge the RDS file with the mapping file
ps0 <- merge_phyloseq(ps0, map)

# Perform a few sanity checks
sample_variables(ps0)
ntaxa(ps0)
rank_names(ps0)
get_taxa_unique(ps0, "Phylum")

```
##Factor reordering and renaming (optional)

The default sorting for ggplot2 is alphabetical. So if you want to make a box plot comparing Shannon diversity between wild-type and knockout mice, it will by default always place knockout on the left and wild-type on the right. However, you may wish to switch this so the knock-out is on the right and wild-type on the left.

This can be done on a plot-by-plot basis, however, it is likely that you will want all of your plots to reflect this customization throughout the entire analysis, so it is useful to have an R chunk at the very beginning of your workflow to specify order and label names.

In the example data, most of the analysis will be done comparing the sample variable "treatment" which is either KoolAid or Ampicillin in the mapping file. Due to default ordering, Ampicillin will always appear before Koolaid. We want the control displayed first (on the left of most plots). We also want to use the more formal "Vehicle" to indicate that a "vehicle control" was used. Koolaid is added to the water to encourage mice to drink the antibiotic laden water. This would be indicated in the methods of a manuscript, but the plots should be more formal and indicate that this was a vehicle control. The code chunk below provides examples for reordering and relabeling sample variable data.

```{r factor-adjustments}
# Examine the way the sample data look now
levels(sample_data(ps0)$Treatment)

# Reorder it so vehicle appears first
sample_data(ps0)$Treatment <- factor(sample_data(ps0)$Treatment, levels = c("Koolaid", "Ampicillin"))
levels(sample_data(ps0)$Treatment)

# Change Koolaid into Vehicle
sample_data(ps0)$Treatment <- factor(sample_data(ps0)$Treatment, labels = c("Vehicle", "Ampicillin"))

# Check that it worked as you expected
sample_data(ps0)$Treatment

```
##ASV summary statistics

Data assessment consists of 2 steps:

1) Evaluate Amplicon Sequence Variant (ASV, formerly referred to as an OTU) summary statistics
2) Detect and remove outlier samples

Begin by running the following R chunk to produce several summary plots and basic statistics about the ASV's and samples in your data.

```{r data-assessment}
# Create a new data frame of the sorted row sums, a column of sorted values from 1 to the total number of individuals/counts for each ASV and a categorical variable stating these are all ASVs.
readsumsdf = data.frame(nreads = sort(taxa_sums(ps0), TRUE), 
                        sorted = 1:ntaxa(ps0),
                        type = "ASVs")


# Add a column of sample sums (total number of individuals per sample)
readsumsdf = rbind(readsumsdf,
                   data.frame(nreads = sort(sample_sums(ps0), TRUE),
                              sorted = 1:nsamples(ps0),
                              type = "Samples"))

# Make a data frame with a column for the read counts of each sample for histogram production
sample_sum_df <- data.frame(sum = sample_sums(ps0))

# Make plots
# Generates a bar plot with # of reads (y-axis) for each taxa. Sorted from most to least abundant
# Generates a second bar plot with # of reads (y-axis) per sample. Sorted from most to least
p.reads = ggplot(readsumsdf, aes(x = sorted, y = nreads)) +
  geom_bar(stat = "identity") +
  ggtitle("ASV Assessment") +
  scale_y_log10() +
  facet_wrap(~type, scales = "free") +
  ylab("# of Sequences")

# Histogram of the number of Samples (y-axis) at various read depths
p.reads.hist <- ggplot(sample_sum_df, aes(x = sum)) + 
  geom_histogram(color = "black", fill = "firebrick3", binwidth = 150) +
  ggtitle("Distribution of sample sequencing depth") + 
  xlab("Read counts") +
  ylab("# of Samples")

# Final plot, side-by-side
grid.arrange(p.reads, p.reads.hist, ncol = 2)

# Basic summary statistics
summary(sample_sums(ps0))

```

There is an R script in the /scripts directory called plot_violin which encapsulates that entire R chunk into a single command.

The above data assessment is useful for getting an idea of 1) the overall taxonomic distribution of your reads (left plot). This will normally be a "long tail" with some taxa being highly abundant in the data tapering off to taxa with very few reads, 2) probably more valuable than the first plot is how many reads are in each sample (middle plot). Very low read count can be indicative of a failed reaction and 3) a histogram of the number of samples at various "bins" of read depth. Each of these plots will help give an understanding of how your data are structured across taxa and samples and will vary depending on the nature of your samples.

Samples with unexpectedly low number of sequences can be safely removed. This is an intuitive process and should be instructed by your understanding of the samples in your study. For example, if you have 5 samples from stool samples, one would expect to obtain thousands, if not several thousands of ASVs. This may not be the case for other tissues, such as spinal fluid or tissue samples. Similarly, you would not expect thousands of ASV from samples obtained from antibiotic treated organisms. Following antibiotic treatment you may be left with dozens or hundreds of ASVs. So contextual awareness about the biology of your system should guide your decision to remove samples based on ASV number. The basic idea is to remove samples with "unexpected" numbers of ASV.

Importantly, at each stage you should document and justify your decisions. If you are concerned that sample removal will alter the interpretation of your results, you should run your analysis on the full data and the data with the sample(s) removed to see how the decision affects your interpretation.

The above plots provide overall summaries about the number of ASVs found in all of your samples. However, they are not very useful for identifying and removing specific samples. This can be done using the following R chunk.

```{r sample-removal-identification}
# Format a data table to combine sample summary data with sample variable data
ss <- sample_sums(ps0)
sd <- as.data.frame(sample_data(ps0)) # useful to coerce the phyloseq object into an R data frame
df <- merge(sd, data.frame("ASVs" = ss), by ="row.names") # merge ss with sd by row names. Rename ss to ASVs in the new data frame

# Plot the data by the treatment variable

y = 50 # Set a threshold for the minimum number of acceptable reads. Can start as a guess
x = "Treatment" # Set the x-axis variable you want to examine
label = "Well" # This is the label you want to overlay on the points that are below threshold y. Should be something sample specific

p.ss.boxplot <- ggplot(df, aes_string(x, y = "ASVs", fill = x)) + # x is what you assigned it above
  geom_boxplot(outlier.colour="NA") +
  scale_y_log10() +
  geom_hline(yintercept = y, lty = 2) + # Draws a dashed line across the threshold you set above as y
  geom_jitter(alpha = 0.5, width = 0.15, size = 2)
  # geom_text(aes_string(x, y="ASVs", label=label), size=3, nudge_x = 0.1) # This labels a subset that fall below threshold variable y and labels them with the label variable
p.ss.boxplot

```

(In progress) There is an R script in the /scripts directory called plot_violin which encapsulates that entire R chunk into a single command.

The example data does have a couple of samples with fewer than 500 ASVs. However, these come from samples obtained from antibiotic treated mice, so this fits our expectation. There is also a single sample with fewer than 1,000 ASVs in the control data which is extraordinarliy low compared to the other samples. This sample should definitely be considered for removal. When questionable samples arise you should take note of them, so if there are samples which behave oddly in downstream analysis you can recall this information and perhaps justify their removal. The following R chunk shows how to identify and remove samples if needed.

```{r sample-removal}
# Use the same 'subset' strategy to plot text on only those samples with fewer than y numbers of ASVs to produce a table of samples
low.ASV.samples <- subset(df, ASVs <= 1000) # Set the number to 1,000 to capture that one sample in vehicle control that is lower than 1,000
low.ASV.samples

# You can use this data to find a unique identifier to remove those specific samples
ps0 # View the original number of samples
ps1 <- ps0 %>%
  subset_samples(
    Name != "806rcbc347"
  )
ps1 # The sample number should be reduced according to your expectations

```
##Overall sample relationship to evaluate sample outliers

Note that we created a new phyloseq object called ps1. This preserves all of the data in the original ps0 and creates a new data object with the offending sample(s) removed called ps1.

Failure to detect and remove "bad" samples can make interpreting ordinations much more challenging as they typically project as "outliers" severely skewing the rest of the samples. These samples also increase variance and will impede your ability to identify differentially abundant taxa between groups. So sample outlier removal should be a serious and thoughtful part of every analysis in order to obtain optimal results.

The next code chunk implements an MDS plot of Bray-Curtis dissimilarity. This is a simple projection of multivariate data and can be useful for identifying sample outliers similar to what we just did above. However, this takes into consideration the entire properties of the data set, and not just number of ASVs. If outliers are suspected based on this plot one should consider their removal.

```{r outlier-sample-evaluation}
# Outlier evaluation
out.bray <- ordinate(ps1, method = "MDS", distance = "bray")
p.MDS.outlier <- plot_ordination(ps1, out.bray, color = "Treatment", axes = c(1,2)) +
  theme_bw() +
  geom_point(size = 2) +
  ggtitle("MDS of Bray Distances \nOutlier Evaluation") +
  geom_text(aes(label = Well), size = 3, check_overlap = FALSE, vjust = -1)
p.MDS.outlier

```
## Outlier sample removal

You can see when we color code the points by treatment that there are three samples that are intermediate between Vehicle and Ampicillin treatment (labelled G1, H1, and H3), and one Ampicillin sample behaving like a Vehicle treated sample (sample F1). The samples were intentionally labelled by the sample well from the 96-well plate that was used in library creation. It is very common for the edge wells (rows A or H and columns 1 and 12) to have a higher failure rate due to evaporation during thermal cycling. Overlaying the well coordinates as text on the ordination plot shows that the samples exhibiting unexpected behavior were amplified in edge wells, except the H3 sample. Knowing the well position along with the unexpected behavior allows us to make the safe decision that these samples are likely unrepresentative of the experiment and can be justifiably documented and removed.

If you recall the violin plot generated to detect sample outliers above, there were also four samples from the Ampicillin treated samples with unexpectedly high numbers of ASVs. We did not consider those earlier, but this MDS plot suggests that there are samples from Ampicillin treated mice behaving like samples from Vehicle control mice. If you redraw the violin plot but overlay "Well" as the text variable for all samples and not a subset, you will see that samples G1, H1, H3 and in particular the sample in F1 have ASV numbers similar to the Vehicle control mice.

The fact that three of these came from edge wells is a strong argument for their removal. The sample in H3 is a more challenging decision. These samples could just be representative of the natural biological variability in the effectiveness of Ampicillin treatment in mice. Perhaps the antibiotics just didnt work as well in the mouse used in well H3.

Sample removal decisions should be made thoughtfully and considering biological and technical context. Again, the appropriate way to handle this is to document and test the affect of the removal. For this example, I am choosing to remove all of the outlier samples as indicated by the MDS and ASV violin plots (samples in well G1, H1, F1 as well as the curious sample in H3). I am doing so because I want to also exclude variance due to failed Ampicillin treatment which these plots are in support of.

```{r outlier-sample-removal}
# Note: DO NOT remove based on well number. Each run uses several 96-well plates, so removal by well number will potential remove serveral samples
# Always use a unique ID for sample removal

ps1 # View the original number of samples
ps2 <- ps1 %>%
  subset_samples(
    Name != "806rcbc348" &
    Name != "806rcbc360" &
    Name != "806rcbc374" &
    Name != "806rcbc372"
  )
ps2 # The sample number should be reduced according to your expectations

# You can redraw the plot to confirm removal
out.bray.removed <- ordinate(ps2, method = "MDS", distance = "bray")
p.MDS.outlier.removed <- plot_ordination(ps2, out.bray.removed, color = "Treatment") +
  theme_bw() +
  geom_point(size = 2) +
  ggtitle("MDS of Bray Distances \nOutliers Removed")
p.MDS.outlier.removed

```
##Taxon prevalence estimations and filtering

Low abundant taxa typically do not contribute to ecological community evaluation or differential abundnace testing. There are of course caveats to this statement (i.e. low-abundance pathogen detection), but many analysis can benefit from the removal of uninformative (low prevalence) taxa. Removal of low prevalence taxa greatly assist in tests penalized with a false-discovery-rate (FDR) calculation. Similar to outlier sample removal, low prevalent taxa removal should be justified and documented. The following R chunk provides several evaluations and plots to assist with this decision.

```{r prevalence-assessment}
# Begin by removing sequences that were not classified as Bacteria or were classified as either mitochondria or chlorplast

ps2 # Check the number of taxa prior to removal
ps2 <- ps2 %>%
  subset_taxa(
    Kingdom == "k__Bacteria" &
    Family  != "f__mitochondria" &
    Class   != "c__Chloroplast"
  )
ps2 # Confirm that the taxa were removed

# Note the prefix (e.g. k__, f__, c__, etc.) is a GreenGenes convention. If you are using RDP or Silva you can simply remove these prefixes.

# To remove ASVs lacking phyla classification
#ps2 <- subset_taxa(ps2, !is.na(Phylum) & !Phylum %in% c("","uncharacterized"))

# prevalence estimation
# Calculate feature prevalence across the data set
prevdf <- apply(X = otu_table(ps2),MARGIN = ifelse(taxa_are_rows(ps2), yes = 1, no = 2),FUN = function(x){sum(x > 0)})

# Add taxonomy and total read counts to prevdf
prevdf <- data.frame(Prevalence = prevdf, TotalAbundance = taxa_sums(ps2), tax_table(ps2))

# Create a table of Phylum, their mean abundances across all samples, and the number of samples they were detected in
plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})

#Prevalence plot
prevdf1 <- subset(prevdf, Phylum %in% get_taxa_unique(ps0, "Phylum"))
p.prevdf1 <- ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(ps2),color=Family)) +
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) +
  geom_point(size = 3, alpha = 0.7) +
  scale_x_log10() +
  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) +
  theme(legend.position="none") +
  ggtitle("Phylum Prevelence in All Samples\nColored by Family")
p.prevdf1

```

The code below can be reproduced using the script called plot_prevalance.R in the scripts folder.

This code will produce a table and a plot of all of the Phyla present in your samples along with information about their prevalence (fraction of samples they are present in) and total abundance across all samples. For this data, you can see from the table that the Cyanobacteria and Deferribacteres have both low prevalence and overall abundance. This is reflected in the plot which displays all of the unique taxa within each family. The points are colored by family, so you can see that there is only one type of Cyanobacteria and Deferribacteres, but lots of Firmicutes. There is also a ubiqutous Tenericute in the data along with another more randomly distributed Tenericute.

The plot also shows a dashed line that was subjectively chosen to cross at 5% prevalence. Everything below this line is present in fewer than 5% of all of the samples in the study.

Both the table and the plots can be used to remove low prevalent taxa. This can be done by either choosing to remove specific taxa (e.g. Deferribacteres or Cyanobacteria from the example data), or remove all taxa above or below a given threshold (e.g. below 5% prevalence). If you choose to do this you should justify and document. You should also consider analyzing both data (data with all taxa vs. data with low-prevalent taxa removed) to observe the effects of taxa removal. This will be useful for understanding how low-prevalent taxa removal influences your results. Low-prevalence filtering is a common practice precedding differential abudnace testing. Low prevalent taxa create harsh penalties on statistical tests due to multiple testing penalties and it is common practice to remove them. The R chunk below describes how to perform taxon filtering.

For the sake of example, we will go ahead and remove the low-prevalence Deferribacteres and Cyanobacteria. There is no biological basis behind this, and it would actually be detrimental if you were interested in the biology of either type of organism. But statistically they are not going to provide much information about community diversity across samples. On the other hand, they probably will not cause any problems either, so would normally be safe to leave them in. We will remove them just as an example. We will also make a new phyloseq object with taxa < 5% prevalence removed called ps3.prev.


```{r prevalence-filtering}
# Remove specific taxa
# Define a variable with taxa to remove
filterPhyla = c("p__Deferribacteres", "p__Cyanobacteria")

ps2 # Check the number of taxa prior to removal
ps3 <- subset_taxa(ps2, !Phylum %in% filterPhyla) 
ps3 # Confirm the taxa were removed

# Removing taxa that fall below 5% prevalence
# Define the prevalence threshold
prevalenceThreshold = 0.05 * nsamples(ps3)
prevalenceThreshold

# Define which taxa fall within the prevalence threshold
keepTaxa <- rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps3 # Check the number of taxa prior to removal
ps3.prev <- prune_taxa(keepTaxa, ps3)
ps3.prev # Confirm the taxa were removed

```
##Data transformation

Many analysis in community ecology and hypothesis testing benefit from data transformation. Many microbiome data sets do not fit to a normal distribution, but transforming them towards normality may enable more appropriate data for specific statistical tests. The choice of transformation is not straight forward. There is literature on how frequently used transformations affect certain analyses, but every data set may require different considerations. Therefore, it is recommended that you examine the effects of several transformations on your data and explore how they alter your results and interpretation.

The R chunk below implements several commonly used transformations in microbiome research and plots their results. Similar to outlier removal and prevalance filtering, your choice should be justified, tested and documented.

```{r data-transform}
# Transform to Realative abundances
ps3.ra <- transform_sample_counts(ps3, function(OTU) OTU/sum(OTU))

# Transform to Proportional Abundance
ps3.prop <- transform_sample_counts(ps3, function(x) min(sample_sums(ps3)) * x/sum(x))

# Log transformation moves to a more normal distribution
ps3.log <- transform_sample_counts(ps3, function(x) log(1 + x))

# View how each function altered count data
par(mfrow=c(1,4))
plot(sort(sample_sums(ps3), TRUE), type = "o", main = "Native", ylab = "ASVs", xlab = "Samples")
plot(sort(sample_sums(ps3.log), TRUE), type = "o", main = "log Transfromed", ylab = "ASVs", xlab = "Samples")
plot(sort(sample_sums(ps3.ra), TRUE), type = "o", main = "Relative Abundance", ylab = "ASVs", xlab = "Samples")
plot(sort(sample_sums(ps3.prop), TRUE), type = "o", main = "Proportional Abundance", ylab = "ASVs", xlab = "Samples")
par(mfrow=c(1,1))

# Histograms of the non-transformed data vs. the transformed data can address the shift to normality
p.nolog <- qplot(rowSums(otu_table(ps3))) + ggtitle("Raw Counts") +
  theme_bw() +
  xlab("Row Sum") +
  ylab("# of Samples")

p.log <- qplot(log10(rowSums(otu_table(ps3)))) +
  ggtitle("log10 transformed counts") +
  theme_bw() +
  xlab("Row Sum") +
  ylab("# of Samples")

grid.arrange(p.nolog, p.log, ncol = 2)

```
##Subsetting (optional)

You will frequently find that you want to analyze a subset of your total data set. There are typically commands that will allow you to do this for each individual analysis, but similar to variable reordering it can sometimes be more convenient to do this towards the beginning of your analysis. This should be done after removal of outlier samples and taxa. If you wish to create transformed versions of each subset you can either subset the transformed data you just generated, or alternatively retransform your subsetted data. The R chunk below is an example subsetting of the example data by treatment.

Subsetting away samples can create a situation where taxa are present as empty rows. This is because not every sample has every taxa. These can be removed as shown in the R chunk below.

Creating individual subsets like this can be particularly useful when assessing differential abundance using DeSeq2.

```{r subsetting}
# Make a subset of mice treated with Ampicillin
ps3 # Check the original number of samples
ps3.amp <- subset_samples(ps3, Treatment == "Ampicillin")
ps3.amp # Check that the number of samples is correct following the subsetting

any(taxa_sums(ps3.amp) == 0) # In this case it is TRUE, so remove the zero's
ps3.amp <- prune_taxa(taxa_sums(ps3.amp) > 0, ps3.amp)
ps3.amp # Number of taxa should be smaller now
any(taxa_sums(ps3.amp) == 0) # It should now be false

# Make a subset of mice treated with Vehicle
ps3 # Check the original number of samples
ps3.vehicle <- subset_samples(ps3, Treatment == "Vehicle")
ps3.vehicle # Check that the number of svehicleles is correct following the subsetting

any(taxa_sums(ps3.vehicle) == 0) # In this case it is TRUE, so remove the zero's
ps3.vehicle <- prune_taxa(taxa_sums(ps3.vehicle) > 0, ps3.vehicle)
ps3.vehicle # Number of taxa should be smaller now
any(taxa_sums(ps3.vehicle) == 0) # It should now be false

```
##Community composition plotting

Bar plots can be useful for examining overall taxon representation across your samples. Importantly, they do not portray any information about the overall abundance of each taxa (just relative abundance) and should not be used for making anything more than high-level visual representations of the community composition of your data.

```{r community-composition-plots}
# Create a data table for ggploting
ps3_phylum <- ps3 %>%
  tax_glom(taxrank = "Phylum") %>%                     # agglomerate at phylum level
  transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance (or use ps0.ra)
  psmelt() %>%                                         # Melt to long format for easy ggploting
  filter(Abundance > 0.01)                             # Filter out low abundance taxa

# Plot - Phylum
p.ra.phylum <- ggplot(ps3_phylum, aes(x = Name, y = Abundance, fill = Phylum)) + 
  geom_bar(stat = "identity", width = 1) +
  facet_grid(~Treatment, scales = "free_x") +
  theme(axis.text.x = element_blank()) +
  theme(axis.title.x = element_blank()) +
  ggtitle("Abundant Phylum (> 1%)")
p.ra.phylum

# Note: This is a nice place to output tables of data that you may want to use for other analysis, or to include as supplemental data for publication
# You can rerun the first bit of code in this chunk and change Phylum to Species for a table with all possible classifications
write.table(ps3_phylum, file = "phylum_relab.txt", sep = "\t")

ggplotly(p.ra.phylum)

```

These plots show that Ampicillin treatment changes the ratio of Bacteroidetes to Firmicutes and results in the expansion of Tenericutes and Proteobacteria.

##Alpha diversity analysis

Alpha diversity is diversity of species on a local scale such as a specific environmental sampling site or patient sample. Species diversity consists of two components: species richness and species evenness. Species richness is simply the count of species at a site while species evenness takes into account there abundances. Equal abundances indicates high evenness and low diversity, unequal abundnaces indicates low evenness and high diversity.

The basic properties can be useful for determining high-level differences between study groups. Importantly, they do not take into account any taxonomic information, so any differences you see require further investigations into what taxa are driving differences in alpha diversity.

To test for differences in alpha diversity we will compare the mean diversity of different diversity measures between groups using a t-test and use box or violin plots for display. The R chunk below implements two measures: 1) Observed which is the observed number of species, or richness, 2) Shannon Diversity which is a standard diversity measure. Other measures are available in estimate_richness options.

## Alpha diversity summary information generation

```{r add-sample-data}
# Diversity
diversity <- global(ps3)
head(diversity)

sd.3 <- as.data.frame(sample_data(ps3)) # useful to coerce the phyloseq object into an R data frame
ps3.rich <- merge(sd.3, diversity, by ="row.names") # merge sd.1 by row names

# Add divergence measurements
ps3.rich$divergence <- divergence(ps3)

```

```{r alpha-diversity}
p.rich.treatment <- ggboxplot(ps3.rich, x = "Treatment", y = "richness_0", outlier.shape = NA) +
  geom_jitter(width = 0.2) +
  # facet_grid(~Week) +
  ylab("Richness") +
  theme(axis.title.x = element_blank()) +
  stat_compare_means(method = "t.test")

p.sd.treatment <- ggboxplot(ps3.rich, x = "Treatment", y = "diversities_shannon", outlier.shape = NA) +
  geom_jitter(width = 0.2) +
  # facet_grid(~Week) +
  ylab("Shannon diversity") +
  theme(axis.title.x = element_blank()) +
  stat_compare_means(method = "t.test")

grid.arrange(p.rich.treatment, p.sd.treatment, ncol = 2)

```

Analysis of alpha diversity along continuous variables can be visualized using visually weighted regression plots (http://www.fight-entropy.com/2012/07/visually-weighted-regression.html).

```{r alpha-diversity-regression}
# The plot_regression command from the microbiome package requires phyloseq objects
# For the violin plots above we combined alpha diversity measurements with sample data as a data frame to generate ggplot ready data
# We will take the same approach here, but will combine alpha diversity measurements with sample data in the phyloseq object to prepare it for microbiome

# Diversity
diversity.vehicle <- global(ps3.vehicle)
diversity.amp <- global(ps3.amp)
head(diversity.amp)

# Combine diversity into metadata
sample_data(ps3.vehicle)$Shannon <- diversity.vehicle$diversities_shannon
sample_data(ps3.vehicle)$Richness <- diversity.vehicle$richness_0

sample_data(ps3.amp)$Shannon <- diversity.amp$diversities_shannon
sample_data(ps3.amp)$Richness <- diversity.amp$richness_0

colnames(sample_data(ps3.vehicle))
colnames(sample_data(ps3.amp))

p.regr.veh <- plot_regression(Shannon ~ Richness, meta(ps3.vehicle), spag = FALSE, shade = FALSE, show.lm = TRUE) +
  ggtitle("Vehicle Control Mice") +
  ylab("Shannon Diversity") +
  xlab("Richness")

p.regr.amp <- plot_regression(Shannon ~ Richness, meta(ps3.amp), spag = FALSE, shade = FALSE, show.lm = TRUE) +
  ggtitle("Ampicillin Treated Mice") +
  ylab("Shannon Diversity") +
  xlab("Richness")

grid.arrange(p.regr.veh, p.regr.amp, nrow = 2)

```

Correlation between measures of alpha diversity and continuous variables can be assessed using the cor.test function of base R and the corrplot package for measuring multiple variables at once.

```{r alpha-diversity-correlation}
cor.vehicle <- cor(diversity.vehicle)
cor.amp <- cor(diversity.amp)

corrplot(cor.vehicle)
corrplot(cor.amp)

# If you wanted to compare with data with sample metadata you can merge the entire diversity data frame to your sample data
ps3.div.vehicle <- merge(sample_data(ps3.vehicle), diversity.vehicle, by = "row.names")
ps3.div.amp <- merge(sample_data(ps3.amp), diversity.amp, by = "row.names")

# Remove non-numeric variables
ps3.div.vehicle <- select_if(ps3.div.vehicle, is.numeric)
ps3.div.amp <- select_if(ps3.div.amp, is.numeric)

# Remove uninteresting variables, in this case the first 5 variables are not needed
ps3.div.vehicle <- subset(ps3.div.vehicle, select = -c(1:5))
ps3.div.amp <- subset(ps3.div.amp, select = -c(1:5))

# Run correlations
ps3.div.v.cor <- cor(ps3.div.vehicle)
ps3.div.a.cor <- cor(ps3.div.amp)

# Correlation plots
corrplot(ps3.div.v.cor)
corrplot(ps3.div.a.cor)

```

These results demonstrate how the average number of bacteria detected in ampicillin treated mice decreases as expected following antibiotic treatment. The diversity increases which is also reflected through the increase in Tenericutes and Proteobacteria in the community composition bar plots.

##Beta diversity analysis

Beta diversity is the extent of difference in community composition between sites or along a gradient. There are a large number of ways to analyze and visualize beta diversity, but we are basically looking for a ordination to help us determine how different samples from different groups are. For example, we want to project the diversity of each sample as a point across an ordination plot that explains as as much variance in the data as possible and in an unconstrained manner. We then color each sample by a grouping variable (e.g. Treatment, Infection, Disease, Sex) and look for distinct grouping.

One can run statistical tests to determine if the null hypothesis that the groups are not dissimilar should be rejected at a given alpha.

This first R chunk will implement two ordinations using two commonly used phylogenetic diversity measures, unifrac and weighted unifrac. Weighted unifrac takes into account the relative abundnaces of each taxa, while unifrac does not. Both measures take into account the phylogenetic relatedness of each taxa. There are a large number of measures that can be interrogated.

Key factors that one may want to consdier when approaching a beta diversity analysis are:

1) Transformed vs. untransformed data
2) Which data transform to use
3) Distance measure to use

```{r beta-diversity}
# Ordinate
ord.pcoa.uni <- ordinate(ps3, method = "PCoA", distance = "unifrac")
ord.pcoa.wuni <- ordinate(ps3, method = "PCoA", distance = "wunifrac")

# Plots
p.pcoa.uni <- plot_ordination(ps3, ord.pcoa.uni, color = "GroupedCage") +
  geom_point(size=5, alpha = 0.7) +
  geom_point(colour = "grey50", size = 1.5) +
  facet_grid(~ Treatment) +
  stat_ellipse(type = "norm") +
  ggtitle("PCoA | Unifrac")

p.pcoa.wuni <- plot_ordination(ps3, ord.pcoa.wuni, color = "SurvivalStatus") +
  geom_point(size=5, alpha = 0.7) +
  geom_point(colour = "grey50", size = 1.5) +
  facet_grid(~ Treatment) +
  stat_ellipse(type = "norm") +
  ggtitle("PCoA | wUnifrac")

grid.arrange(p.pcoa.uni, p.pcoa.wuni, nrow = 2)

```
For fun the points are color coded by the cage each animal originate from or survival status. The take home message from these plots is that the samples are separated by treatment, and there isn't much of any separation by cage. This is to be expected from the experimental design. The ADONIS test can be used to test if the treatment groups are significantly different.

##Group significance testing with ADONIS

```{r adonis}
# Set a random seed so that exact results can be reproduced
set.seed(1000)

# Function to run adonis test on a physeq object and a variable from metadata 
doadonis <- function(physeq, category) {
  bdist <- phyloseq::distance(physeq, "bray")
  col <- as(sample_data(physeq), "data.frame")[ ,category]
  
  # Adonis test
  adonis.bdist <- adonis(bdist ~ col)
  print("Adonis results:")
  print(adonis.bdist)
  
  # Homogeneity of dispersion test
  betatax = betadisper(bdist,col)
  p = permutest(betatax)
  print("Betadisper results:")
  print(p$tab)
}

# Runs Permanov and Homogeneity of dispersion test
# See ?betadisper for more info
doadonis(ps0, "Treatment")

```
 
You can see from the highly significant p-value that treatment does indeed indicate that the groups are dissimilar. The Homogeneity of Dispersion is a test for how variable the sample groups are. For this data, the significant p-value suggets that the variance is significantly different between the groups as well.

The second doadonis command tests whether or not mice that survived or died as a result of treatment were dissimilar. This example was included as it demonstrates the utility of subsetting as we only wanted to run the test on ampicillin treated samples. 
 
##Differential abundance testing

```{r differential-abundance-testing}
# Differential Abundance - Baseline ~ CD4 and VL Category
ds <- phyloseq_to_deseq2(ps0, ~Treatment) # Change formula to VL_category and rerun to test VL_category
dds <- DESeq(ds, test="Wald", fitType="local", betaPrior = FALSE) # Worth trying parametric and local fitTypes

alpha = 0.05

# Tabulate and write results
res.dds = results(dds, cooksCutoff = FALSE)
sigtab_dds = res.dds[which(res.dds$padj < alpha), ]
sigtab_dds = cbind(as(sigtab_dds, "data.frame"), as(tax_table(ps0)[rownames(sigtab_dds), ], "matrix"))
head(sigtab_dds)
write.table(sigtab_dds, file="./results/deseq_results.txt", sep = "\t") # Change filename to save results to appropriate file

# Simple plot of results
x.ds = tapply(sigtab_dds$log2FoldChange, sigtab_dds$Family, function(x) max(x))
x.ds = sort(x.ds, TRUE)
sigtab_dds$Species = factor(as.character(sigtab_dds$Family), levels=names(x.ds))
p.deseq <- ggplot(sigtab_dds, aes(x=Family, y=log2FoldChange, color=Genus)) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_point(size=5, alpha = 0.7) + 
  theme(axis.text.x = element_text(angle = -90, hjust = 0, vjust=0.5)) +
  ggtitle("Taxa Differentially Associated by Treatment") + 
  geom_hline(yintercept = 0, lwd=1.5)
p.deseq

# Quick check of factor levels
mcols(res.dds, use.names = TRUE)

```
##Volcano plot of differential abundance testing results

Volcano plots are useful for visualizing not only the differentially abundant taxa, but also those taxa which did not pass the alpha threshold. Interactive plots using plotly can aid in interrogating the complex arrangements of points.

```{r volcano-plots-da-results}
# Prepare to join results data.table and taxonomy table
resdt = data.table(as(results(dds, cooksCutoff = FALSE), "data.frame"),
                   keep.rownames = TRUE)
setnames(resdt, "rn", "OTU")
taxdt = data.table(data.frame(as(tax_table(ps0), "matrix")), keep.rownames = TRUE)
setnames(taxdt, "rn", "OTU")

# Join results data.table and taxonomy table
setkeyv(taxdt, "OTU")
setkeyv(resdt, "OTU")
resdt <- taxdt[resdt]
resdt
resdt[, Significant := padj < alpha]
resdt[!is.na(Significant)]
resdt

volcano = ggplot(
  data = resdt[!is.na(Significant)][(pvalue < 1)],
  mapping = aes(x = log2FoldChange,
                y = -log10(pvalue),
                color = Phylum,
                label = OTU, label1 = Genus)) +
  theme_bw() +
  geom_point() + 
  geom_point(data = resdt[(Significant)], size = 7, alpha = 0.7) + 
  # geom_text(data = resdt[(Significant)], mapping = aes(label = paste("Genus:", Genus)), color = "black", size = 3) +
  theme(axis.text.x = element_text(angle = -90, hjust = 0, vjust=0.5)) +
  geom_hline(yintercept = -log10(alpha)) +
  ggtitle("DESeq2 Negative Binomial Test Volcano Plot\nBaseline Samples") +
  theme(axis.title = element_text(size=12)) +
  theme(axis.text = element_text(size=12)) +
  theme(legend.text = element_text(size=12)) +
  geom_vline(xintercept = 0, lty = 2)
volcano

ggplotly(volcano)

```
##Ground truth plots

```{r ground-truth-plots}

replace_counts = function(physeq, dds) {

  dds_counts = counts(dds, normalized = TRUE)
  if (!identical(taxa_names(physeq), rownames(dds_counts))) {
    stop("OTU ids don't match")
  }
  otu_table(physeq) = otu_table(dds_counts, taxa_are_rows = TRUE)
  return(physeq)

}

## Transform
# Convert raw counts to rlog normalized counts
ps3.rlog <- replace_counts(ps1, dds)

# o__Actinomycetales
ps3_Actinomycetales <- ps3.rlog %>%
    subset_taxa(Order == "o__Actinomycetales") %>%
    psmelt()

p.Actinomycetales <- ggboxplot(ps3_Actinomycetales, x = "Treatment", y = "Abundance", outlier.shape = NA, add = "median_iqr") +
  geom_jitter(mapping = aes(size = 2), alpha = 0.4, na.rm = TRUE, width = 0.3) +
  scale_y_log10() +
  ylab("Abundance (rlog)") +
  theme(axis.title.x = element_blank()) +
  theme(legend.position = "NULL") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_grid(~Genus) +
  stat_compare_means(method = "wilcox.test", label = "p.format")
p.Actinomycetales

# Subset deseq2 ID'd sequence
ps3_Actinomycetales.seq <- subset(ps3_Actinomycetales, OTU == "GTAGGGTGCAAGCGTTGTCCGGAATTATTGGGCGTAAAGAGCTCGTAGGCGGTTTGTCGCGTCTGCTGTGAAATCCCGAGGCTCAACCTCGGGCTTGCAGTGGGTACGGGCAGACTAGAGTGCGGTAGGGGAGATTGGAATTCCTGGTGTAGCGGTGGAATGCGCAGATATCAGGAGGAACACCGATGGCGAAGGCAGATCTCTGGGCCGTAACTGACGCTGAGGAGCGAAAGCATGGGGAGCGAAC")
write.table(ps3_Actinomycetales.seq, file = "./results/ps1_Actinomycetales_seq.txt", sep = "\t")

p.Actinomycetales.seq <- ggboxplot(ps3_Actinomycetales.seq, x = "Treatment", y = "Abundance", outlier.shape = NA, add = "median_iqr") +
  geom_jitter(mapping = aes(size = 2), alpha = 0.4, na.rm = TRUE, width = 0.3) +
  scale_y_log10() +
  ylab("Abundance (rlog)") +
  theme(axis.title.x = element_blank()) +
  theme(legend.position = "NULL") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  stat_compare_means(method = "wilcox.test", label = "p.format")
p.Actinomycetales.seq

```

```{r session-info}
# Dsiplay current R session information
sessionInfo()
```
